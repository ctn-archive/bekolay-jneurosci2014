\documentclass[11pt]{article}
\usepackage{amsmath,amsfonts,amsthm,amssymb}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{extramarks}
\usepackage{chngpage}
\usepackage{caption}
\usepackage{namedplus}
\usepackage[usenames,dvipsnames]{color}
\usepackage{graphicx,float}
\usepackage{listings}
\usepackage{framed}
\usepackage{inconsolata}
\usepackage{hyperref}

\hypersetup{
  colorlinks = true, %Colours links instead of ugly boxes
  urlcolor = blue, %Colour for external hyperlinks
  linkcolor = blue, %Colour of internal links
  citecolor = red %Colour of citations
}

% Stuff to change, you know, if you want.
\setlength{\parindent}{1cm}
\setlength{\parskip}{3pt}

% In case you need to adjust margins:
\topmargin=-0.45in      %
\evensidemargin=0in     %
\oddsidemargin=0in      %
\textwidth=6.5in        %
\textheight=9.0in       %
\headsep=0.25in         %

\pagestyle{plain}

\newcommand{\scalefigone}[3]{
  \begin{figure}[ht!]
    % Requires \usepackage{graphicx}
    \centering
    \includegraphics[width=#2\columnwidth]{#1}
    \caption{#3}
    \label{#1}
  \end{figure}}

\setlength\fboxrule{1pt}
\linespread{1.5}

\graphicspath{{../figures/}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Make title
\title{A spiking neural integrator model of the adaptive control of
  action by the anterior cingulate cortex}
\date{Abbreviated title: A spiking model of ACC adaptive control}
\author{%
  Trevor Bekolay \\
  Centre for Theoretical Neuroscience \\
  University of Waterloo \\ ~ \\
  Mark Laubach \\
  The John B. Pierce Lab \\
  New Haven, CT \\ ~ \\
  Chris Eliasmith \\
  Centre for Theoretical Neuroscience \\
  University of Waterloo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\maketitle

\textbf{Corresponding author:} Chris Eliasmith.
Email: \url{celiasmith@uwaterloo.ca}.
Centre for Theoretical Neuroscience, University of Waterloo.
200 University Avenue West, Waterloo, ON, N2L 3G1.

\textbf{Pages:} 24. \textbf{Figures:} 8. \textbf{Tables, multimedia, 3D models:} 0

\textbf{Word counts:} Abstract: 164, Introduction: 445, Discussion: 479

\textbf{Conflict of Interest}
The authors declare no competing financial interests.

\textbf{Acknowledgements}

Financial support: NSF 1121147 to ML;
NSERC Discovery, CRC, CFI, and OIT to CE;
and NSERC CGS-D to TB.
We thank Benjamine Liu for technical contributions
to the modeling effort and
Nandakumar Narayanan who recorded the neurons
that were analyzed by TB and ML.

\clearpage

\begin{abstract}
  Reaction times can be improved by preparing movements
  in advance and by learning the expected timing
  of action-imperative stimuli.
  Success or failure on the previous trial
  can be an important factor for determining
  whether an animal will attempt to time
  the stimulus or simply wait for it to occur
  before initiating action.
  The anterior cingulate cortex (ACC) has been implicated
  in enabling the top-down control of action
  depending on the outcome of the previous trial.
  Analysis of ACC activity suggests that
  neural integration is a key mechanism
  for adaptive control in precisely timed tasks.
  We show through simulation
  that a spiking neural circuit
  consisting of coupled neural integrators
  captures the neural dynamics
  of the experimentally recorded ACC.
  We expand on this coupled integrator model
  to construct a spiking neural circuit that
  performs a reaction time task by following
  either a timing or cue-response strategy,
  and show that it performs a simple reaction time task
  with similar reaction times as experimental subjects.
\end{abstract}

\linespread{1.5}

\section{Introduction}

The anterior cingulate cortex (ACC) has been implicated
in a wide variety of functions,
including conflict monitoring
\cite{Sheth2012,Aarts2009,Botvinick2004,VanVeen2004},
performance monitoring
\cite{Brown2005,Carter1998,Fecteau2003,Modirrousta2008,Rushworth2004,Histed2009,Hyman2013,Horst2012},
anticipatory control \cite{Aarts2008,Koyama2001},
arousal of the sympathetic nervous system
\cite{Critchley2003,Luu2003},
and control of action timing
\cite{Muir1996,Mulert2003,Naito2013,Narayanan2009,Risterucci2003}.
Conceptual models have been proposed
that would allow the ACC to be involved
in several of these functions,
depending on behavioral context
(e.g., \citenoparens{Botvinick2004,Luu2003}).
However, while there have been
attempts at modeling the ACC
using artificial neural networks
\cite{Botvinick2004,Brown2005},
there are currently no mathematical
accounts of ACC function that would
explain the myriad of behaviors
modulated by the ACC.
As well, no existing models
have been implemented with spiking neurons,
and therefore no models can be analyzed
with the same methods used
to analyze single neuron recordings.

In this paper, we propose that a
two-dimensional dynamical system
can account for ACC activity
related to error monitoring and motor action timing.
We test the model in a simple reaction time task
with a predictable foreperiod and
show that the mathematical model
enables precise timing of actions,
and changes behavior depending
on the outcome of the last trial.
The dynamical system is based
on a multi-dimensional attractor
network proposed by \citetext{Singh2006},
and is implemented in a spiking neural network
using the Neural Engineering Framework
(NEF; \citenoparens{Eliasmith2003}).
We show, using identical analyses
to those employed on the experimental data,
that simulated neural activity from this circuit
closely matches recorded ACC activity
and that the model can be combined with
a simple motor control model
to produce behavior consistent
with behavioral studies of simple reaction time tasks.

Our model also provides an alternative hypothesis
of how the ACC accomplishes the control of action timing.
\citetext{Narayanan2009} hypothesized
that ACC activity inhibits motor responses
until the time of the cue.
Our model instead proposes that
ACC activity encodes the duration of the action
and that inhibition is carried out elsewhere.

In this paper we apply our
mathematical account of ACC function
to explain error monitoring and
the control of action timing.
However, we suggest that the dynamical modelling
method we employ is general and can be extended
to explain other theories
of high-level ACC function.

\section{Methods}

\subsection{The reaction time task} \label{sec:simple-rt}

Twelve male Long-Evans rats
were trained to press down on a lever
for a fixed amount of time (the ``foreperiod'';
1 second for this study)
using standard methods \cite{Laubach2000}.
After the foreperiod, a cue is presented
(an auditory tone).
The subject then has 0.6 seconds (the response window)
in which to release the lever.
If the lever is released in that time,
the trial is a success, and the subject is rewarded
with water.
If the lever is released during the foreperiod,
the trial is classified as a ``premature error,''
and is penalized by a time-out with the house lights extinguished.
If the lever is not released within the response window,
the trail is classified as a ``late error,''
and is also penalized by a time-out with the house lights extinguished.
Figure~\ref{fig1} presents a schematic view of the task.
Subjects were considered to have learned the task
when they performed in correctly $> 60 \%$
of the time.

The same reaction time task was simulated
in the Nengo simulation environment
using a finite state machine to track
task state, and scalar values between -1 and 1
to indicate the state of house lights,
lever position, auditory cue, and reward.
The Nengo scripts simulating this environment
are available at
\url{https://github.com/tbekolay/jneurosci2013}.

\subsection{Data analysis}

\subsubsection{Neural data}

The experimental data analyzed in this study is the same
as that in \citetext{Narayanan2009}, in which
the authors recorded the anterior cingulate cortex (ACC) and motor cortex
of rodents performing this simple reaction time task.
(The ACC recordings were made in the prelimbic cortex,
which is a component of the ACC.
The area was referred to as the dorsomedial PFC
in the original paper.)
\citeauthor{Narayanan2009} used principal component analysis
(PCA) to characterize common firing patterns
in the ACC during the task.

In the PCA, only neurons with an average
firing rate over 1 Hz are considered.
Spike trains from 4 seconds prior to and 4 seconds after
each press event on a correct trial are isolated.
Each perievent spike train is binned in 1 ms bins and is then
convolved with a Gaussian filter ($\sigma = $ 25 ms;
PCs are consistent with many other $\sigma$ values).
These spike density functions
are normalized to Z-scores,
and then averaged over all trials to
produce a matrix in which each row is
the normalized average response of a neuron
over the perievent epoch.
Singular value decomposition
is performed on that matrix
to isolate the principal components,
which are then normalized to Z-scores.
The amount of variance accounted for
by each principal component
is computed as the square of the component's eigenvalue
over the sum of all squared eigenvalues
($s_i^2 / \sum s^2$).

As shown in Figure~\ref{fig2},
the first two principal components
of the experimental data
are modulated around the task events
and appear to track
whether the subject has pressed the lever and
the relative amount of time
that the lever has been pressed.
\citeauthor{Narayanan2009} also found that the neural activity
in the ACC changed significantly depending on
the outcome of the previous trial;
the first two principal components
change significantly after errors,
and appear to contain information that an error occurred.
This information would be necessary
in order to adapt behavior based on the last trial.

Interestingly, in the post-correct case,
the first principal component
is highly correlated with the integral
of the second principal component,
and vice versa.
In the post-error case,
these correlations are significantly weaker.
This result suggests that
the ACC is performing some kind of integration,
and that integration depends
on prior behavioral outcomes.

\subsubsection{Behavioral data}

In both the experimental and theoretical studies,
the following relevant event times are recorded:
lever press, lever release, reward delivery,
trigger stimulus onset, and house light extinguishing.
Sequences of event times were used to
identify the result of each trial.
Filtering the set of event timestamps
for these sequences identifies each trial outcome.
Reaction times are calculated
only for correct trials,
and are defined as the difference between
trigger stimulus onset and lever release.

\subsection{Double integrator model}

The double integrator model
was proposed in the context of working memory
by \citetext{Singh2006}.
Their model uses multidimensional neurons
in integrative populations
to exhibit time-varying activity
during a vibrotactile discrimination task.
It relies on two coupled integrators,
whose activity resembles
the two strong principal components
in the ACC data.
The model employs
the Neural Engineering Framework (NEF; \citenoparens{Eliasmith2003})
to implement a spiking neural network
that captures the dynamics of the
integrative dynamical system.
We hypothesize that a model
similar to that proposed by \citeauthor{Singh2006}
will exhibit the same neural dynamics
as the experimental ACC in the simple RT task.

\subsubsection{Dynamics} \label{sec:dynamics}

The dynamics of the double integrator model
are captured in the following dynamics equations:
\begin{align*}
  \dot{x}_1 &= u \\
  \dot{x}_2 &= \alpha x_1,
\end{align*}
where $u$ represents an input signal
and $\alpha$ is the strength of
the connection between the two integrators.
This results in a two-dimensional system
in which $x_1$ integrates its input,
maintaining the accumulated value over time, and
$x_2$ integrates the value of $x_1$.
\citetext{Singh2006} have proposed that this system
enables time tracking.
Because $x_2$ integrates $x_1$,
the amount of time elapsed since
$x_1$ changes can be determined
based on how much $x_2$ has changed.

In the simple RT task,
we want to keep track of how much time
has elapsed since the subject
has pressed the lever.
While the lever press event could be
used as the input to the system,
since we aim to embed this system
in a spiking neural model,
we instead use the activity of the motor neurons
that effect the lever press as
the input, $u$.
The system is also modified by signals
representing the outcome of a particular trial;
on a correct trial, reward delivery ($R > 0$)
resets the system to a starting state.
On an error trail, a second input signal ($E < 0$)
drives $x_1$ to a low state.
When implemented in a spiking network,
this causes $x_2$ to saturate at a low value,
effectively breaking the integration,
as is seen in Figure~\ref{fig2} in post-error trails.
This results in the following overall dynamics.
\begin{align} \label{dint}
  \dot{x}_1 &= u + E - R x_1 \nonumber \\
  \dot{x}_2 &= \alpha x_1 - R x_2.
\end{align}
See Figure~\ref{fig3} for a graphical
depiction of the double integrator model.

The dynamics of Equation \eqref{dint}
are predictable for certain values
of $\alpha$, $E$, and $R$.
$\alpha$ defines how quickly
the system drifts during the task;
we set it such that $x_2 \approx 1$
at the time of release,
which occurs when $\alpha = 0.04$.
If $R$ is sufficiently big,
then when reward is delivered
the system will be driven to the origin.
This occurs when $\int_0^{t_R} R\,dt \ge 1$.
We set the length of reward delivery,
$t_R$, to 1 second to reflect the pace
of the experimental subjects,
and we set the reward magnitude,
$R$, to 0.15 so that $\int_0^{t_R} R\,dt \ge 1$.
Larger values of $R$ would be functionally identical,
as $x_1 = x_2 = 0$ when $R \ge 0.15$ for $t_R$ seconds.
If $E$ is sufficiently low,
then when error is detected,
the system will be driven to
the lowest $x_1$ value that can
be represented by the population
of spiking neurons.
This exploits the saturating nature
of spiking neurons in order to
obtain stability in this
mathematically unstable system.
If $\int_0^{t_E} E\,dt \le -1$,
then the system will saturate
at a low value for $x_1$.
We set $t_E = 2 s$ and $E = -0.06$.

To summarize, there are five parameters
in this dynamical system:
$t_R$ and $t_E$ are set based on the pace
of experimental subjects;
$R$ and $E$ have little behavioral
consequence if $R \ge 0.15$ and
$E \le -0.06$ and are set
to match the experimental principal components;
$\alpha$ is a free parameter
that critically affects the model's success
and is set such that $x_2 \approx 1$
at the time of release.

In addition to the above system,
we inject a slowly oscillating signal into $x_1$.
Having made the parameter choices
described above,
the system is stable during the intertrial
interval in both post-correct and post-error
cases.
However, the experimental data shown in
Figure~\ref{fig2} exhibits some activity during
the intertrial interval;
we capture this additional activity
by introducing a simple oscillation,
$O = \sin(2 \pi f t + \phi)$,
where the frequency $f$ is low ($\le 0.4$Hz).
While there is experimental evidence for
a slow oscillations like $O$ in various brain regions
\cite{Buzsaki2004}, this injected oscillation
does not affect the behavioral performance of the network,
but instead models ACC activity
not being explicitly modelled in
the remainder of the circuit.
This activity could reflect
other functions that the ACC is performing,
or could reflect the overall pace
of the simple RT task.
The final dynamics are
\begin{align} \label{dint-full}
  \dot{x}_1 &= u + E + O - R x_1 \nonumber \\
  \dot{x}_2 &= \alpha x_1 - R x_2.
\end{align}

\subsubsection{Neural Engineering Framework} \label{sec:nef}

Equation~\eqref{dint-full} is implemented
in a spiking neural network using
the principles of the Neural Engineering Framework
(NEF; \citenoparens{Eliasmith2003}).
The NEF enables the simulation of dynamical systems
like Equation~\eqref{dint-full} by
making the assumption that populations of spiking neurons
represent real-valued vectors,
and using a least-squares optimal method
to transform those representations
through the connections between
populations of neurons.
A population can have recurrent connections
in order to produce dynamics,
such as the neural integrators
employed in this study.

The NEF's representation scheme
is similar to population coding,
as proposed by \citetext{Georgopoulos1986},
but extended to $n$-dimensional vector spaces.
Each neuron in a population is sensitive
to a particular direction,
called the neuron's \textit{encoder}.
The activity of a neuron can be expressed as
\begin{equation}
  a = G[\alpha \mathbf{e} \cdot \mathbf{x} + J_{bias}],
\end{equation}
where $G[\cdot]$ is a nonlinear neural activation function,
$\alpha$ is a scaling factor (gain) associated with the neuron,
$\mathbf{e}$ is the neuron's encoder,
$\mathbf{x}$ is the vector to be encoded, and
$J_{bias}$ is the background current of the cell
when $\mathbf{x} = 0$.
The currently encoded value, $\mathbf{\hat{x}}$,
can be estimated linearly:
\begin{equation}
  \mathbf{\hat{x}}(t) = \sum_i \mathbf{d}_i a_i(t),
\end{equation}
where $\mathbf{d}_i$ is the neuron's decoder,
and $a_i$ is activity of neuron $i$.

Neural activity is interpreted as a
filtered spike train.
\begin{equation}
  a_i(t) = \sum_s h(t - t_s) = \sum_s e^{-(t - t_s) / \tau_{PSC}},
\end{equation}
where $h(\cdot)$ is the exponential filter
applied to each spike,
and $s$ is the set of all spikes occurring
before the current time $t$.

Decoders are found through a least-squares minimization
of the difference between the decoded estimate
and the actual encoded vector.
\begin{equation}
  \mathbf{d} = \Upsilon^{-1} \Gamma \hspace{1.8em}
  \Gamma_{ij} = \int a_i a_j dx \hspace{1.8em}
  \Upsilon_j = \int a_j \mathbf{x} dx.
\end{equation}

Connection weights to linearly transform these encoded vectors
can then be computed as
\begin{equation}
  \omega_{ij} = \alpha_j \mathbf{e}_j L \mathbf{d}_i,
\end{equation}
where $i$ indexes the input population,
$j$ indexes the output population,
and $L$ is a linear operator.

% We only do linear transformations I think?

% Connection weights computing a function
% between two populations connected in a feedforward manner
% $f(\mathbf{x})$ can be determined by
% solving for a set of decoding weights
% for that function,
% \begin{equation}
%   \mathbf{d}^{f(\mathbf{x})} = \Upsilon^{-1} \Gamma \hspace{1.8em}
%   \Gamma_{ij} = \int a_i a_j dx \hspace{1.8em}
%   \Upsilon_j = \int a_j f(\mathbf{x}) dx,
% \end{equation}
% and then computing the following weight matrix, $\omega$;
% \begin{equation}
%   \omega_{ij} = \alpha_j \mathbf{e}_j L \mathbf{d}^{f(\mathbf{x})}_i,
% \end{equation}
% where $i$ indexes the input population,
% $j$ indexes the output population,
% and $L$ is a linear operator.

Dynamical systems of the form
$\dot{\mathbf{x}} = A(\mathbf{x}) + B(\mathbf{u})$
can be created by connecting a population
to itself with the linear operator
$L = A$ on the recurrent connection,
and receiving input $\mathbf{u}$
from other populations and
setting $L = B$ on those connections.

These principles can be used for any neuron model,
$G[\cdot]$. In this study, we use the
adaptive leaky integrate-and-fire (ALIF) model
to match \citetext{Singh2006}.
For each instance of each model,
the parameters of each ALIF neuron
is randomly selected from within
a biologically constrained range.
The encoders, $e_i$, are randomly selected
directions in the encoded vector space.
All other parameters in the simulation
are computed from these parameters,
or are described in section \ref{sec:dynamics}.

\subsection{Adaptive control circuit}

\citetext{Narayanan2009} hypothesized
that ACC activity could be used
to inhibit motor responses
until the time of the cue.
An alternative view is that neuronal activity
serves to encode the duration of the action
and that inhibition is carried out elsewhere.
To examine these hypotheses,
we constructed a network that
performs the simple RT task
using the non-adaptive strategy
of responding to cues.
We then combined that network
with the double integrator network
to give an overall ``adaptive control circuit''
that is able to switch between
an aggressive timing strategy
and a conservative cue-response strategy
depending on the outcome of the previous trial.

\subsubsection{Cue-responding circuit} \label{sec:cue-responding}

The cue-responding circuit is composed
of three populations
of adaptive leaky integrate-and-fire neurons
(see Figure~\ref{fig3}, grey box only).
The population labelled \textit{Trigger}
is sensitive to the cue.
The population labelled \textit{Holding}
tracks whether the lever is currently being held down.
The population labelled \textit{Press/Release}
causes lever presses and releases
through activation of different subsets
of its neurons.
The actual lever press and release
is delayed by $\sim$200ms,
the approximate amount of time
it takes for muscles to respond
to sensory input \cite{Kawato1999}.

The \textit{Holding} neurons project
to the \textit{Trigger} population
to provide the behavioral context
(i.e., \textit{can} I release the lever?)
The \textit{Trigger} neurons send projections
to the \textit{Press/Release} neurons
upon a cue that occurs in the correct context
(i.e., \textit{should} I release the lever?)

The context-driven design of this circuit
provides an alternative theory to
the prepotent inhibition model
proposed by \citetext{Narayanan2009}.
They suggest that a motor command
is activated at the same time
as an inhibitory waiting signal,
and it is the removal of that inhibition
that produces the motor command.
This model proposes that
an excitatory context signal is activated,
and the pairing of that context signal
with the cue produces the motor command.
This leads to an alternative hypothesis
for the function of ACC activity:
the ACC tracks the behavioral context,
and is able to inhibit or excite motor cortex,
but does not always necessarily do so.

\subsubsection{Adaptive control circuit}

A weakness of the contextual cue-responding circuit
is that there is a fixed lower-bound
on the reaction time
based on the time taken to detect the cue
and for the delay between activation
of motor cortex and muscle activity.
Since the goal is to produce the action
as close as possible to the time of the cue,
the cue-responding strategy may be too slow,
and so a predictive approach must be employed.

The double integrator model described
previously can be combined with the
cue-responding circuit to implement such a strategy
(see Figure~\ref{fig3}).
The state of the dynamical system being tracked by
the double integrator (Equation [\ref{dint-full}])
is approximately the same each trial when the cue occurs.
By connecting the output of the double integrator
to the \textit{Trigger} population,
the double integrator can cause a lever release
when the state of the double integrator
is slightly before the predicted
time of the cue.

However, if the previous trial was an error,
the double integrator will not
be following the trajectory
that predicts the time of the cue,
and therefore will not cause a lever release.
The circuit then naturally
uses the conservative
cue-responding strategy.
Switching between these two strategies
depending on the outcome
of the previous trial
allows for adaptive control of action timing.
A possible extension to this model
would incorporate synaptic plasticity
to change the recurrent connections such that
the cue prediction would be better
on subsequent trials.

\section{Theoretical results}

\subsection{Model dynamics during the simple RT task}

Here we describe the results of solving
the dynamical system in equation \eqref{dint} directly
(i.e., not using neurons).
This provides a general characterization
of the expected low-dimensional dynamics
of the high-dimensional neural simulation.
Figure~\ref{fig4} demonstrates that
this dynamical system exhibits
the behavior described in section \ref{sec:dynamics} during
correct, premature, and late trials.
Note that this figure depicts equation \eqref{dint},
which does not have the oscillatory term $O$.
The final position of
the trajectory becomes the starting position
of the next trial, and therefore
provides information about
the outcome of the last trial.

It is clear from these trajectories
that the time of the cue
can be predicted,
as the ACC is only in the predictive state
when the cue occurs on correct trials.
It is also clear that the
outcome of the previous trials
is easily decoded based
on the state after the previous trial.
Note that premature trials
and late trials cannot be distinguished
on the next trial;
this is consistent with the results of
\citetext{Narayanan2009}.

These theoretical results suggest that
the underlying, low-dimensional dynamics
of the postulated circuit
should be appropriate
for capturing the qualitative features of ACC activity.
We now examine
both the qualitative and quantitative fit
of the high-dimensional spiking network
to the recorded empirical data.

\section{Simulation results}

\subsection{Spiking networks follow predicted trajectories}

Figure~\ref{fig5} shows that
the decoded values of a spiking neural network
with the same dynamics as equation \eqref{dint-full}
also take a similar trajectory through
state space in correct, premature, and late trials.
Despite the introduction of the oscillation
and the additional noise present
in spiking neural systems,
behaviorally relevant states
are significantly separated
in the decoded state space of the spiking model.
Therefore, the cue can be predicted,
and the outcome of the previous trial
has a significant effect
on the trajectory taken during a trial.

\subsection{The double integrator model has the same principal components as the experimental data}

In order to perform an identical
principal component analysis
on the simulated data as was done
on the experimental data,
we adopted the methods of the original paper
and randomly sampled 174 neurons
with firing rates $> 1$ Hz from
the spiking double integrator model.
The spike trains of these neurons
were convolved with the same Gaussian filter
as used experimentally
($\sigma = $ 25 ms)
and then normalized to Z-scores.
The results are shown in Figure~\ref{fig6}.
The simulated principal components
are very similar to the experimental principal components
\cite{Narayanan2009}:
$R^2 = 0.96$ and $R^2 = 0.895$ for
the first two components in the post-correct case,
$R^2 = 0.979$ and $R^2 = 0.877$ for
the first two components in the post-premature case,
and $R^2 = 0.967$ and $R^2 = 0.862$ for
the first two components in the post-late case.
$R$ is a Pearson correlation coefficient in all cases.

\subsection{The adaptive control model explains observed performance}

Figure~\ref{fig7} shows the performance
of the experimental subjects,
the model using only the cue-responding strategy,
and the full adaptive model.
The length of the simulations were
varied to match the number of trials
performed by subjects.
The mean of the median reaction times
is 272$\pm$48ms for the experimental subjects,
368$\pm$34ms for the cue-responding models,
and 260$\pm$100ms for the adaptive control model.
The mean performance (\% correct trials) is
70.8\% for experimental subjects,
96.9\% for cue-responding models,
and 84.0\% for adaptive control models.
Therefore, only the adaptive control model
has statistically indistinguishable reaction times
compared to the experimental subjects.
The cue-responding model is significantly slower,
but makes fewer errors than the adaptive control model.

\subsection{Cue prediction causes premature releases}

Figure~\ref{fig8} shows the decoded values
of neural populations during representative trials
of the cue-responding and adaptive control circuits.
In panel C, the double integrator model
causes the control model to respond faster than
the cue-responding strategy.
Premature release never occurs with
the cue-responding circuit alone.
While this cannot be directly compared
with the experimental data,
as we cannot determine
whether the experimental subject
is attempting to
predict the time of the cue,
it suggests that more premature
releases will occur when the time of the cue
can be predicted;
if the foreperiod randomly varied, for example,
our model predicts that fewer premature
releases would occur.

\section{Discussion}

Our results indicate that the double integrator model
allows for adaptive control of action timing.
The ability to predict the time of the cue
produces faster reaction times at the cost
of additional premature errors.
The model that enables this adaptive control
has very similar neural dynamics
as the experimental ACC.

One important difference between
the experimentally recorded and simulated ACC
is in the amount of variance
explained by the principal components
and the lack of noise in
spike densities (see Figure~\ref{fig6}).
The relative cleanness of the simulated data
is expected for several reasons.
Primarily, we expect that the ACC
is sensitive to many other factors
than are represented in the simulation.
The simulated data is more analogous
to the 174 neurons in the entire ACC
that are modulated the most during the simple RT task,
rather than the 174 neurons that happened
to be recorded during the experiments.
Increased variability could be simulated
by either injecting
noise into the simulation,
or by representing additional
randomly varying dimensions.

An interesting feature of the model
is that there is significant randomness
involved in model generation (see section~\ref{sec:nef}).
This results in significant variability
in the performance of simulated subjects,
despite all but one performing the task well
(see Figure~\ref{fig7}).
Also interesting is that the model is
not plastic; the weights determined
before the simulation do not change.
The ability to keep track of the state
of the system over time through recurrent connections
is what enables the model to adapt.
This points to a need for models to
differentiate between adaptability
due to recurrent activity
and adaptability due to
synaptic weight changes.

While we have tested our mathematical model
of ACC function in the context of
control of action timing in a simple RT task,
the tracking of behavioral variables
in a dynamical system could be used
to perform many of the other high-level functions
that the ACC is theorized to perform.
For example, in the commonly studied Stroop task,
the state space being tracked by
the ACC could be the difference between
the response suggested by word-reading and the
response suggested by the color;
the context in which colors should be read
would be reflected in the passive dynamics
of the ACC, which would push the ACC
to increasingly drift towards a state
that compensates for the word-reading response.
Similar mappings could be proposed
for a wide variety of ACC-monitored tasks.

In conclusion, we have shown that neural integration
is likely a key mechanism in the ACC's
ability to control the timing of actions.
Analysis of the activity of a neural integrator
model closely matches that of the experimentally recorded ACC.
That model is sufficient to allow
a simple cue-responding network
to react more quickly at the cost
of additional errors,
which matches the performance of experimental subjects.

\bibliographystyle{namedplus}
\bibliography{jneurosci2013}

\clearpage

\section{Legends}

\paragraph{Figure 1}

The simple reaction time task used in the experiment.
Trials are classified as correct, premature, or late
depending on the time of lever release.

\paragraph{Figure 2}

A summary of the principal component analysis done
in \citetext{Narayanan2009};
the motivation for investigating \citetext{Singh2006}.
(A) A graphical summary of principal component analysis.
Nomarlized perievent neural data,
in the form of the Z-scores of instantaneous firing rates,
is organized in a matrix, with each row
being the Z-scored firing rates
of a single neuron on a single trial.
Singular value decomposition is performed on the matrix,
resulting in a matrix such that
the number of columns (time bins) is the same.
The rows are now ordered such that the first row
contains largest eigenvector,
which represents the value when the original
data is projected onto the axes of highest variance.
(B) The fraction of variance explained
by each singular value
when PCA is performed on the post-correct neural data
(top), and the post-error data (bottom).
In both cases, the two eigenvectors with the highest
singular values account for nearly 50\% of variance.
The next two eigenvectors also account for an amount
of variance higher than would be expected when
we linearly interpolate from the smaller
singular values.
(C) A summary of the loadings of the two top
eigenvector on each neuron.
If a neuron were encoding both the first and second
eigenvectors to the same degree,
we would expect a horizontal line.
The varied lines criss-crossing each other
suggest that each individual neuron
has different sensitivities
to the first and second principal components.
(D) The top three principal components
for the post-correct trials (black)
and the post-error trials (red).
(E) (Top) Plotting the cumulative sum (integral)
of the first principal component closely matches
the second principal component, and vice-versa
(Pearson $R^2 = 0.904$ and $R^2 = 0.939$ respectively),
in the post-correct case.
(Bottom) In the post-error case,
the first two principal components are no longer
cumulative sums of each other
(Pearson $R^2 = 0.639$ and $R^2 = 0.676$).
This points to neural integration
as a potential mechanism explaining ACC activity.
(F) Normalized spike-density functions
for all of the neurons analyzed in the post-correct case,
organized by the loading
(left) on the first principal component, and
(right) on the second principal component.

\paragraph{Figure 3}

Block diagram of the adaptive control model.
(Left) The adaptive control model contains
the double integrator model,
from \citetext{Singh2006}.
It has been modified by accepting
both press information ($u$)
and error information ($E$)
to drive $x_1$, and
reward information ($R$)
to control the integration
of both $x_1$ and $x_2$.
The output of the double integrator,
colored red, is the only component
that interacts with the cue-responding
circuit, by activating neurons
in the \textit{Trigger} population.
(Middle) The cue-responding circuit
that is able to perform
the simple reaction time task
by responding to the Cue
provided by the environment
(see section \ref{sec:cue-responding}).
(Right) Values that are not modeled
with spiking neural populations,
and are therefore considered
signals that are provided by the environment.
The lever accepts the decoded
output of the \textit{Press/Release} population,
lowering after \textit{Press} sensitive
neurons are activated (following some delay),
and raising after \textit{Release} sensitive
neurons are activated (following the same delay).

\paragraph{Figure 4}

A detailed breakdown of the dynamics and
trajectory the model takes through state space
for (A) correct, (B) premature, and (C) late trials
following a correct trial.
The injected oscillation is omitted
in these plots;
its time dependence makes it misleading
to draw vector fields for a particular time.
(A) In a correct trial, the pressing of the lever
sends the double integrator model's state into
the upper part of the state space.
The connection between the two integrators
causes the passive dynamics (panel 2)
to push the state towards the right.
The cue is delivered while drifting
to the right, and the release occurs
in the upper-right portion of the state space.
After successful release,
the reward turns off both integrators,
causing the system to return to the origin point,
where it remains until the next trial.
(B) In a premature trial, the lever is released
prior to the onset of the cue (panel 2).
Premature release causes
the house lights to extinguish,
which drives the system to
a point in the lower part of the state space.
Between trials (panel 4),
the passive dynamics of the state space
drive the system to the lower-left portion
of the space, where it will be
at the start of the next trial.
(C) In a late trial, the cue occurs,
but the lever is not released (panel 2).
Late release causes
the house lights to extinguish,
which drives the system
to a point in the lower part of the state space.
Between trials (panel 4), the passive dynamics
of the state space drive the system
to the same lower-left portion of the space
that premature errors result in.
Therefore, late and premature errors
cannot be distinguished on the next trial.

\paragraph{Figure 5}

Decoded values of the double integrator model
simulated in spiking neurons.
The spiking neural model takes
very similar trajectories through state
space as the mathematical model (see Figure~\ref{fig4}).
Similar to the mathematical model,
the spiking model represents a very different state
after correct (left) and error (middle, right)
trials.

\paragraph{Figure 6}

Results of principal component analysis
on the data generated by the double integrator model
for correct presses in (A) post-correct trails,
(B) post-premature trials, and (C) post-late trials.
The top row of panels compares
the top two principal components
of the model to those of the experimental ACC data.
In all cases, the PCs are significantly similar
(Pearson $R^2 > 0.86$).
The middle row of panels shows normalized
peri-event spike densities
for 174 randomly sampled neurons from the
simulated double integrator model.
The bottom row of panels shows normalized
peri-event spike densities
for all 174 neurons recorded
during the experimental study.
The patterns of sensitivity
compared in the middle and bottom rows
are similar, although the recorded neuron responses
are more variable over time.

\paragraph{Figure 7}

Behavioural performance of the
experimental subjects and
the cue-responding and adaptive control models.
The top row of panels summarizes the number of
correct, premature, and late trials
for each experimental or simulated subject.
The number of total trials
for the simulations was approximately
matched to the experimental subjects.
The bottom row of panels summarizes the reaction times
on correct trials for each subject.
The dotted black line represents
the mean of all subjects' median reaction times.

\paragraph{Figure 8}

Decoded values from representative trials.
The labels above denote events;
`P' is a lever press event,
`C' is a cue onset event,
`R' is a lever release event,
`E' is an error delivery event,
and `Rw' is a reward delivery event.
Names of the decoded signals correspond
to the names of populations in Figure~\ref{fig3}.
(A) A correct trial using the cue-responding circuit.
In the cue-responding network, the trigger neurons
activate only once the cue is delivered.
Trigger neurons activate the release neurons,
which initiate the release of the lever.
There is a delay ($\sim 250ms$)
between the activation of release neurons
and the actual release of the lever.
(B) A correct trial using the adaptive control circuit.
In the adaptive network, when
in the appropriate state, the cue
can be predicted by the double integrator model,
causing the activation of trigger---and
therefore release---neurons before
the time of the cue. This results
in a faster reaction to the cue.
(C) A premature trial using the adaptive control circuit.
Premature release occurs when
the double integrator model incorrectly predicts
the time of the cue.
This occurs when integration is too fast,
and the trigger neurons are activated
such that a lever release is effected
before the time of the cue.
Note that the non-adaptive cue-responding
circuit cannot make premature releases,
because releases are critically dependent
on cue information.
(D) A late trial using the cue-responding circuit.
Late release occurs when
the release neurons are not sufficiently
active in order to effect the lever release.
Alternatively, late release can occur
if the release signal is not faithfully
transmitted from the release neurons
(modeling activity in motor cortex)
to the intermediate populations
(modeling activity between motor cortex and muscles)
before interfacing with the simulated environment.
A late release in the adaptive model
looks identical, with little activity
in the double integrator model that predicts cues.

\section{Figures}

\scalefigone{fig1}{0.5}{}

\scalefigone{fig2}{1.0}{}

\scalefigone{fig3}{0.8}{}

\scalefigone{fig4}{1.0}{}

\scalefigone{fig5}{1.0}{}

\scalefigone{fig6}{1.0}{}

\scalefigone{fig7}{1.0}{}

\scalefigone{fig8}{1.0}{}

\end{document}